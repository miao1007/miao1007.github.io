<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="description" content="本文从应用侧调度软件开始介绍调度器，并主要以单机版OS为例，介绍了CGroups的隔离。"><meta name="keyword" content="CGroups,Docker,Nomad,PaaS"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,minimum-scale=1,user-scalable=no"><meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Nomad调度框架对CGroups的使用</title><link rel="icon" href="data:image/svg+xml,%3Csvg width='24' height='28' xmlns='http://www.w3.org/2000/svg'%3E%3Ctext font-size='24' y='24'%3E諺%3C/text%3E%3C/svg%3E" type="image/x-icon"><link href="/styles/site.css" rel="stylesheet"><meta name="generator" content="Hexo 5.4.0"></head><body class="container"><header id="header"><div class="header"><div class="header-left"><div class="author"><div class="author-name"><a href="/">諺</a></div></div></div><div class="header-right"><ul class="navigation"><li><a href="/archives">Archives</a></li><li style="font-size:.9rem"><a href="/archives" rel="nofollow">zh</a></li><li style="font-size:.9rem"><a href="#" rel="nofollow">|</a></li><li style="font-size:.9rem"><a href="/en" rel="nofollow">en</a></li><li><a href="/tags" rel="nofollow">Tags</a></li><li><a href="/about" rel="nofollow">About</a></li><li><a href="/epistemology" rel="nofollow">Epistemology</a></li><li><a href="/books" rel="nofollow">読書</a></li></ul></div></div></header><div class="content-wrapper"><div class="post"><section class="article"><div class="title">Nomad调度框架对CGroups的使用</div><div class="date">2020-03-18に投稿</div><div class="content"><p>本文从应用侧调度软件开始介绍调度器，并主要以单机版OS为例，介绍了CGroups的隔离。</p><span id="more"></span><p>面向读者：已经有Docker等使用经验，但是希望更深入了解的人。不适用于Java初学者，也不适用于内核级专家。注意本文较长。</p><p>在阅读本文前，我个人建议直接去阅读RedHat的<a target="_blank" rel="noopener" href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/resource_management_guide">文档</a>，专职团队的文档质量肯定比很多博客写的更加好。</p><h2>调度器的介绍</h2><h4>什么是调度</h4><p>所谓调度，就是将资源在一定时间内对任务（Workload）的分配与隔离，比如最简单的切蛋糕，到复杂的PaaS容器编排，再到现实生活的敏捷迭代、打车、外卖都是调度。不过本文主要介绍的是单机版CGroup调度。</p><p>我们可以分类</p><ul><li>简单调度：上下文无关，用贪心算法即可，满足当前最优</li><li>复杂调度：是对复杂系统的处理，或者叫做NP问题，在短期很难有最优解</li></ul><h4>调度软件的介绍</h4><p>常见的有LXC, Docker(Runc), Nomad(新但是部署复杂), Mesos, Platform LSF, Kubernetes等。它们既可以用于HPC作科学计算，也可以用作PaaS服务Web业务。</p><p>我在日常开发中， 使用过多种调度器</p><ul><li>Kubernetes：这个众所周知了，用起来方便，配合各种方法学实施，大部分Web应用都能很好地部署、扩容与滚动发布。缺点是它本身的运维/插件/网络部署太重了，YAML(特别是annotaion/CRD)学习与方言比较<a target="_blank" rel="noopener" href="https://noyaml.com/">陡峭</a>，中小团队投入的运维成本可能比纯Tomcat还高，所以用k8s的前提是有人帮你运维或者买现成的。</li><li>Nomad：一款新的调度框架，对Docker/Raw都有支持，它的安装部署很简单（单个Go文件即可），功能也够用，而且支持广域网调度（基于Consul转发），我个人主要用它来做Jenkins的动态扩容。这个坑也不少，比如它的raw_exec下是<a target="_blank" rel="noopener" href="https://github.com/hashicorp/nomad/issues/7627">不支持</a>cpu/mem/网络限制的，但却开了ns隔离，但是文档没写。</li><li>HPC类：比如IBM LSF/COMSOL Multiphysics，在中科大的超算或者大型芯片公司的仿真使用，费用很贵而且受到USA出口管制，但是功能强大，主要基于核数/MPI框架进行调度，可以管理上千台机器（基本上都是28核以上每台），千万级HPC任务。它有叫做OpenLava的开源实现版，但是被IBM的律师给整残了。更多可以参考这位的<a target="_blank" rel="noopener" href="http://bbs.eetop.cn/forum.php?mod=viewthread&amp;tid=599928&amp;page=1&amp;authorid=219415">博文</a></li><li>iSulad/volcano：由HW的实验室开发，详见<a target="_blank" rel="noopener" href="https://openeuler.org/zh/docs/20.03_LTS/docs/Container/iSula%E5%AE%B9%E5%99%A8%E5%BC%95%E6%93%8E.html">这里</a>与<a target="_blank" rel="noopener" href="https://volcano.sh/en/docs/architecture/">这里</a></li></ul><p>此外有</p><ul><li>多云编排调度，比如Terraform</li><li>数据中心/HPC超算的调度方案，比如Atlas/TaiShan的ARM算力集群等，这种是硬件级门槛</li><li>应用层的Workflow调度，比如Jenkins的CPS编排，Flink的管道计算，ARM的Lava等</li></ul><p>但是它们不再本文介绍范围内。</p><p>唠叨这么多，主要就是想告诉大家，调度是一个广阔的领域，虽然读者与我可能是IT/互联网行业，但是不要限制自己的视野止于“应用”经验。更广阔的底层调度软硬件，编译器，国内极少数企业才能烧钱研发的。</p><h4>总体调度策略</h4><p>大部分调度器总体策略基本如下</p><ul><li>在OS外: 通过BinPack等算法让正确的资源分给需要的任务进行规划调度，一般需要维护状态机/队列。它的难点在于约束，目前主流的调度方法均是求出当前最优解，而不考虑未来。这个玩意太烧钱了，是一般人永远也达不到的天花板，大部分产品都是西方高校或者实验室才能搞出来。</li><li>在OS内: 主要通过CGroups（由谷歌开源）进行调度，如果OS不支持CGroup或者非Root模式，那么可能会需要全表扫描<code>/proc</code>定位PID（比如Jenkins实现了<code>ps</code>读取<code>/proc</code>），但是性能较弱。我个人认为CGroups本质上就是PID的倒排索引，实现了避免全表扫描。在Docker/Nomad中，<a target="_blank" rel="noopener" href="https://github.com/opencontainers/runc">Runc</a>是底层容器框架，它的规格与实现由多家厂商（比如RedHat/HW等）制定规范，是2016年后容器的事实标准。它将CGroups/chroot等命令封装为Go的SDK（<a target="_blank" rel="noopener" href="https://github.com/opencontainers/runc/tree/master/libcontainer">libcontainer</a>），而不用命令行去管理CGroups。</li></ul><h4>有哪些资源可以被隔离调度？</h4><p>更多可以看libcontainer的<a target="_blank" rel="noopener" href="https://github.com/opencontainers/runc/tree/master/libcontainer">参数配置</a></p><blockquote><p>关于CGroups（Control Groups），网上有手动命令行的介绍，比如Redhat的文档就很详细。但是值得注意的是，根据阿姆达尔定律，能够并行的计算是有限的。</p></blockquote><h2>CPU调度</h2><h4>CFS调度介绍</h4><p><a target="_blank" rel="noopener" href="https://www.kernel.org/doc/Documentation/scheduler/sched-design-CFS.txt">CFS</a>通过vruntime维护了每个进程的总虚拟运行时间（实际运行时间*加权），并用红黑树实现优先级的排序，总时间越少的排在前面。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进程结构体的如下信息将在 cfs_rq 树中进行排序</span></span><br><span class="line">task_struct -&gt; sched_entity(contains the vruntime) -&gt; rb_node</span><br></pre></td></tr></table></figure><p>在CGroup中，通过干预权重，使vruntime更低，更加容易被优先调度到</p><p>它在内核开关内部如下</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> CONFIG_RT_GROUP_SCHED</span></span><br><span class="line">  <span class="comment">// 这里以及其它配置</span></span><br><span class="line">  init_rt_bandwidth(&amp;root_task_group.rt_bandwidth, global_rt_period(), global_rt_runtime());</span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>这个宏表示</p><blockquote><p>This option allows you to create arbitrary task groups using the “cgroup” pseudo filesystem and control the cpu bandwidth allocated to each such task group</p></blockquote><p>更多参考：<a target="_blank" rel="noopener" href="https://developer.ibm.com/tutorials/l-completely-fair-scheduler/?mhsrc=ibmlearning_l&amp;mhq=cfs">https://developer.ibm.com/tutorials/l-completely-fair-scheduler/?mhsrc=ibmlearning_l&amp;mhq=cfs</a></p><h4>CFS硬分配（Docker主导）</h4><p>此方案是按照CPS时钟进行划分，也是Docker/Kubernetes的默认实现，不管当前机器是否空闲，它都只能限制到固定的算力，这样应用可能会缺少爆发力(burst)。此方案与主频是无关的。如下是以Docker为例，分别分配4核/1核/0.5核的场景，注意Linux文档中，并没有说<code>100000</code>就一定是一个核心，这里只是一个常见的默认值</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># one second, the default value in containers</span></span><br><span class="line">cpu.cfs_period_us = 100000;</span><br><span class="line"><span class="comment"># allocated cpus = x core</span></span><br><span class="line">cpu.cfs_quota_us = x*100000;</span><br></pre></td></tr></table></figure><p>我在CI构建中，也显示配置了这些最大总硬限制，防止某些不可控的应用把整个OS给搞挂。</p><h4>cpu.shares软限制（Nomad主导）</h4><p>此参数为相对值，与CFS中的<code>vruntime</code>的权重成反比，强调是占用了<code>相对值/SUM(相对值)</code>，而不是固定的频率/核数，使用它的潜规则是你的OS中只能基于一个容器平台维护，否则每个平台映射的含义可能不同。</p><p>在 Nomad框架中，将主频与此一一映射对应，假如定义了1234Mhz的CPU资源，那么在<code>cpu.shares</code>也将配置为1234。我认为这个是最好的思路，它将相对值转为了主频总和的绝对值分配问题。</p><p>在Docker中，默认一核为1024，但是这个开关默认没有打开。</p><blockquote><p>具体如何影响内核，可以参考<a target="_blank" rel="noopener" href="https://qiita.com/nocknocknock/items/89682731cd6e35cdbe27">cpu.sharesの内部動作</a></p></blockquote><h4>高级使用（混合配置）</h4><p>假设你想对某个任务软性限制 300MHz主频，硬性限制一个CPU，可以如下配置。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cpu.shares = 300</span><br><span class="line">cpu.cfs_period_us = 100000;</span><br><span class="line">cpu.cfs_quota_us = 100000;</span><br></pre></td></tr></table></figure><p>再次强调这里的值都是相对值，只有机器内所有CGroup全部遵循这个要求才能说shares约等于主频。</p><h4>cpuset（按照核数调度，LSF主导）</h4><p>当启动任务时，指定CPU的核数，<code>bsub -n 8</code>表示使用了8个物理CPU。此类场景主要是涉及到License或者对Context/cache affinity的任务，比如某些工业软件/科学计算通过CPU个数进行授权，运行费用甚至比CPU本身还贵。而且这类机器基本都是NUMA+关闭超线程，因为超线程/低配CPU在这种场景下软件授权是赔本的。这种一般需要租赁bare metal machine云主机算力。</p><h2>Memory控制</h2><h4>程序内存的组成</h4><p>在一个程序启动后。有如下内存将被分配，假如我启动了一个bash，它将进行如下分配</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动一个Bash程序</span></span><br><span class="line">bash</span><br><span class="line"><span class="comment"># 查看内存映射分配</span></span><br><span class="line">pmap $$ -X</span><br><span class="line"><span class="comment"># 按照真实地址维度计算的话</span></span><br><span class="line"><span class="comment"># 用户态的内存分别是  TEXT, HEAP, LIB, STACK，共约115M，有些共享的内存可能会重复统计</span></span><br><span class="line"><span class="comment"># 按照是否共享Lib库的维度，分别有VSS, R(Resident)SS，P(Proportional)SS, U(Unique)SS</span></span><br><span class="line"><span class="comment"># 注意CGroup控制的是“RSS总量”</span></span><br></pre></td></tr></table></figure><p>值得注意</p><ul><li>CGroup对RAM的统计比较激进，只统计RSS用量，共享库会重复统计。</li><li>在纯运算调度器中（比如LSF调度器），内存占用都特指物理内存PSS（自己占用+共享库均分）的统计。比如你启动多个JVM，可以发现平均占用还降低了。或者OS将你的内存扔到分页里面了，导致内存统计维度占用显得很低。</li></ul><blockquote><p>更多参考：<a target="_blank" rel="noopener" href="http://linuxperf.com/?cat=7">http://linuxperf.com/?cat=7</a></p></blockquote><h4>使用CGroups进行RSS内存限制</h4><p>如果需要限制内存总量，主要有如下配置进行限制</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 物理RAM内存限制，比如2G，这里是k8s等调度器的首选项</span></span><br><span class="line">memory.limit_in_bytes</span><br><span class="line"><span class="comment"># 物理+Swap限制，比如4G，一般推荐是 -1(不限制) 或者 物理内存*2</span></span><br><span class="line">memory.memsw.limit_in_byte</span><br><span class="line"><span class="comment"># 当程序需要内存时，系统分配给程序的既可以是物理内存，也可能是分页缓存</span></span><br><span class="line"><span class="comment"># 这里表示OS优先使用物理内存还是分页，默认是60，越小更倾向于分配物理内存，如果为0将请求关闭虚拟内存</span></span><br><span class="line"><span class="comment"># 强调一下，这里只是请求，实际分配取决于各个内核厂商的实现</span></span><br><span class="line">memory.swappiness</span><br><span class="line"><span class="comment"># 使用统计 rss + cache</span></span><br><span class="line">memory.usage_in_bytes</span><br></pre></td></tr></table></figure><p>至于是否配置虚拟内存比例，有如下场景</p><ul><li>如果是WebService/K8S类应用，一般默认会配置<code>swappiness</code>为0（The kubelet right now lacks the smarts to provide the right amount of predictable behavior here across pods.），这样基于物理内存的统计调度更加简单准确，当全部内存（RAM）耗尽时，取决于<a href="%5Bhttps://kubernetes.io/docs/tasks/administer-cluster/out-of-resource/#node-oom-behavior">node-oom-behavior</a>，通常是Kill掉，这时你要引入JVM监控工具，分析为啥挂了</li><li>如果是高性能计算，原则上不限制SWAP，需要配置昂贵的SAS SSD进行swap配置，一般是2倍。</li></ul><p>测试代码</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /sys/fs/cgroup/memory/<span class="built_in">test</span>/test-1</span><br><span class="line"><span class="comment"># 限制总内存为1M</span></span><br><span class="line">cgset -r memory.memsw.limit_in_bytes=1M /<span class="built_in">test</span>/test-1</span><br><span class="line"><span class="comment"># 只有1M内存，理所当然无法启动</span></span><br><span class="line">cgexec -g memory:/<span class="built_in">test</span>/test-1 bash</span><br><span class="line">cgset -r memory.memsw.limit_in_bytes=128M /<span class="built_in">test</span>/test-1</span><br><span class="line"><span class="comment"># 成功启动了</span></span><br><span class="line">cgexec -g memory:/<span class="built_in">test</span>/test-1 bash</span><br></pre></td></tr></table></figure><h4>使用RDMA技术</h4><p>基于RDMA协议跨过网线访问内存，但是此技术也是非单机版的，不介绍。</p><h2>Nomad对CGroup资源的管理</h2><p>在Nomad中，假如我希望配置某个任务的CPU/内存，那么一般是这样的（raw_exec下不适用此场景）</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">resources &#123;</span><br><span class="line">  memory = <span class="number">128</span> <span class="comment"># MB</span></span><br><span class="line">  cpu    = <span class="number">500</span> <span class="comment"># MHz</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>它在内部将在如下位置生成CGroups</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">drivers&#x2F;shared&#x2F;executor&#x2F;executor_linux.go:configureCgroups</span><br></pre></td></tr></table></figure><p>转化如下</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// runc容器的配置项</span></span><br><span class="line"><span class="comment">// （物理）内存大小</span></span><br><span class="line">cfg.Cgroups.Resources.Memory = mb * <span class="number">1024</span> * <span class="number">1024</span></span><br><span class="line"><span class="comment">// 关闭分页，这里比较坑，没有上游配置就直接写死0了</span></span><br><span class="line">cfg.Cgroups.Resources.MemorySwappiness = <span class="number">0</span></span><br><span class="line"><span class="comment">// 配置weight</span></span><br><span class="line">cfg.Cgroups.Resources.CpuShares = <span class="keyword">uint64</span>(cpuShares)</span><br></pre></td></tr></table></figure><p>其中内存很好理解，CPU就比较有趣了，它居然没有计算直接就透传给了<code>runc</code>库以启动容器，所以再次可以看出，cpushares只是一个影响内核权重的相对值，并不是与核数/频率对应。</p><h2>总结</h2><p>当前CGroup调度器主要就是一个内核系统的外壳，Docker等组件并不是非常复杂。如果需要了解内部实现，需要去学习内核。如果对CGroup有兴趣，可以研究HPC开源平台OpenLava代码，它是纯CGroup而没有namespace，分析更简单。</p><h2>参考</h2><ul><li><p><a target="_blank" rel="noopener" href="http://crosbymichael.com/creating-containers-part-1.html">http://crosbymichael.com/creating-containers-part-1.html</a></p></li><li><p>コンテナ仮想、その裏側 - <a target="_blank" rel="noopener" href="https://www.slideshare.net/Retrieva_jp/user-namespacerootless-141274787">https://www.slideshare.net/Retrieva_jp/user-namespacerootless-141274787</a></p></li></ul></div><div class="tags"><a class="tag-link" href="/tags/CGroups/" rel="tag">CGroups</a><a class="tag-link" href="/tags/Docker/" rel="tag">Docker</a><a class="tag-link" href="/tags/Nomad/" rel="tag">Nomad</a><a class="tag-link" href="/tags/PaaS/" rel="tag">PaaS</a></div></section><ul class="nav"><li>Prev:<a href="/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E4%B8%AD%E7%BD%91%E7%BB%9C%E5%B1%82%E6%8A%BD%E8%B1%A1%E4%B8%8E%E6%94%B9%E8%BF%9B/">微服务中网络层抽象与改进</a></li><li>Next:<a href="/linux%E9%9A%94%E7%A6%BB%E4%B8%8E%E8%B0%83%E5%BA%A6%E3%80%8Cnamespace%E3%80%8D/">Linux隔离与调度「Namespace」</a></li></ul><div class="comments"><div id="disqus_thread"><noscript>Please enable JavaScript to view the<a target="_blank" rel="noopener" href="http://disqus.com/?ref_noscript">comments powered by Disqus</a></noscript></div></div></div></div><footer><div class="rights"><a href="/feed.xml" rel="external nofollow">RSS</a><span>, Theme </span><a href="https://github.com/gary-Shen/hexo-theme-bear" rel="external nofollow" target="_blank">Curry</a><span>.</span></div></footer><script>window.onload=function(){var a,e,n,t;a=window,e=document,t="script",n="ga",a.GoogleAnalyticsObject=n,a.ga=a.ga||function(){(a.ga.q=a.ga.q||[]).push(arguments)},a.ga.l=+new Date,n=e.createElement(t),t=e.getElementsByTagName(t)[0],n.async=1,n.src="//www.google-analytics.com/analytics.js",t.parentNode.insertBefore(n,t),ga("create","UA-102296742-1","auto"),ga("send","pageview")}</script></body></html>